# Education & Guidance (EG) - Data Domain Assessment Questionnaire
## HAIAMM v2.1

---

## Purpose

This questionnaire assesses organizational maturity in establishing and maintaining education and guidance programs that enable teams to effectively operate AI-driven data security and privacy compliance. It evaluates training programs, awareness campaigns, privacy compliance education, and knowledge-sharing practices specific to the Data domain.

---

## Instructions

- Answer each question honestly based on current organizational practices
- Select "Yes" only if you have documented evidence of the practice
- Provide specific evidence in the "Evidence Repository" section
- Calculate your maturity level using the scoring guide at the end

---

## Level 1: Foundational (0-3 points)

### Question 1.1: Foundational Privacy and AI Data Security Training

**Question:** Have all data security, privacy, legal, and data owner teams received foundational training on AI data security and privacy regulations?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Privacy regulations overview training delivered:
  - GDPR compliance training (Article 6 lawful basis, Article 22 automated decisions, Article 25 privacy-by-design, DPIAs)
  - CCPA/CPRA compliance training (consumer rights, do-not-sell obligations, automated decision-making opt-outs)
  - HIPAA compliance training (if applicable)
  - PCI-DSS compliance training (if applicable)
  - Sector-specific privacy regulations covered

- [ ] AI data security capabilities training delivered:
  - Automated data discovery and classification
  - DLP (Data Loss Prevention) enforcement
  - Access anomaly detection
  - Data exfiltration monitoring
  - AI classification accuracy and limitations

- [ ] Data classification principles training delivered:
  - Classification tiers (public, internal, confidential, restricted)
  - Sensitive data types (PII, PHI, PCI, trade secrets)
  - AI classification limitations (false positives, context misunderstanding, need for human validation)
  - Data subject rights overview (right to know what AI monitors, right to explanation, opt-out rights)

- [ ] Role-appropriate training delivered to all audiences:
  - **Data Security Teams**: AI data security tools deep dive (DLP, CASB, data classification, access monitoring)
  - **Privacy Teams**: AI privacy compliance support (DPIA requirements, data subject rights, consent management)
  - **Data Owners**: Business stakeholder training (data classification responsibilities, AI recommendations)
  - **Employees**: General workforce awareness (what AI monitors, privacy protections, acceptable data use)
  - **Developers**: Secure data handling training (privacy-by-design, AI data security APIs)

- [ ] Training completion tracked:
  - Completion rates documented per audience
  - Target: ≥80% completion rate for all required audiences
  - Completion dashboard or tracking system in place

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

### Question 1.2: Privacy Awareness Campaigns

**Question:** Are awareness campaigns actively communicating AI data privacy protections to employees and customers?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Privacy protection messaging implemented:
  - Communications explain how AI data security enhances privacy (detects unauthorized access, prevents breaches, enforces data minimization)
  - Transparency communications on what AI monitors and why
  - Privacy wins shared (successful data exfiltration detection, overprivileged access identification, prevented breaches)
  - Privacy rights awareness materials (how to request data access, understand AI decisions, raise privacy concerns)

- [ ] Employee privacy awareness:
  - Updated privacy notices explain AI data security monitoring
  - Employee communications about workplace data monitoring with AI
  - What data is monitored, why, and how privacy is protected
  - Employee opt-out rights communicated (where applicable)

- [ ] Customer privacy awareness:
  - Customer communications about data protection AI capabilities
  - Privacy policy updates explain AI data security
  - Customer data rights communicated (GDPR Article 15-22 rights, CCPA consumer rights)

- [ ] Executive privacy awareness:
  - Leadership briefed on privacy obligations and AI data security value
  - Regulatory compliance risks and benefits communicated
  - Customer trust and competitive advantage of privacy protection highlighted

- [ ] Trust-building measures:
  - Data Protection Officer (DPO) involved in AI data security awareness
  - Regular privacy audit results shared transparently
  - Ethical AI commitments communicated (fairness, transparency, accountability, privacy protection)

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

### Question 1.3: Privacy Training Completion Tracking

**Question:** Is privacy training completion tracked with target completion rates defined for different audiences?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Training tracking system implemented:
  - Learning Management System (LMS) or tracking platform in use
  - Completion rates tracked per audience segment
  - Training completion reports generated regularly (at least quarterly)
  - Overdue training escalation process

- [ ] Target completion rates defined:
  - **Data Security Teams**: ≥95% completion (critical role)
  - **Privacy Teams**: ≥95% completion (critical role)
  - **Legal/GRC Teams**: ≥90% completion
  - **Data Owners**: ≥85% completion
  - **Developers**: ≥85% completion
  - **General Employees**: ≥80% completion

- [ ] Basic privacy compliance guidance available:
  - GDPR compliance runbook for AI data security
  - CCPA compliance runbook for AI data security
  - HIPAA compliance runbook (if applicable)
  - Data classification quick reference guide
  - DSAR (Data Subject Access Request) handling procedure

- [ ] Training effectiveness baseline:
  - Pre-training privacy knowledge assessment conducted
  - Post-training assessment shows knowledge improvement
  - Training satisfaction surveys collected (target: ≥3.5/5 average rating)

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

## Level 2: Comprehensive (4-6 points)

### Question 2.1: Role-Based Privacy Training with Hands-On Scenarios

**Question:** Are role-based privacy training programs implemented with hands-on scenarios for privacy compliance operations (DSAR handling, DPIA, breach response)?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Role-based training programs delivered:
  - **Data Security Engineers**: Operating AI data security tools (DLP configuration, data classification tuning, access policy enforcement, false positive remediation)
  - **Privacy Officers/DPO**: Using AI for privacy compliance (automated DPIA processes, data subject rights fulfillment, consent management, privacy incident response)
  - **Compliance Analysts**: Auditing AI data security (evidence collection, control testing, regulatory reporting, compliance dashboards)
  - **Data Stewards**: Managing data classification (reviewing AI classification recommendations, approving data policies, data inventory management)
  - **Legal/GRC Teams**: Understanding AI privacy legal implications (AI as data processor, liability for AI errors, regulatory examination preparation)

- [ ] Hands-on privacy compliance scenarios implemented:
  - **Data Classification Exercises**: Lab with sample datasets to practice reviewing/validating AI classification, correcting misclassifications, tuning classification rules
  - **DSAR Fulfillment Practice**: Handling Data Subject Access Requests with AI assistance (locate personal data, redact third-party data, generate DSAR response within 30-day requirement)
  - **Privacy Incident Response Simulation**: Breach scenarios where AI detects unauthorized access (breach assessment, notification decisions, regulatory reporting practice)
  - **DLP Policy Configuration Lab**: Configure AI DLP policies for different data types (PII, PHI, PCI, trade secrets) and test effectiveness
  - **Access Review Exercises**: Use AI-assisted access reviews to identify overprivileged users and certify appropriate access
  - **Cross-Border Transfer Scenarios**: Validate data transfer compliance with AI monitoring (Standard Contractual Clauses, adequacy decisions)

- [ ] Privacy compliance labs available:
  - GDPR Article 30 Records of Processing Activities (ROPA) generation with AI
  - CCPA data inventory and consumer rights request handling
  - HIPAA minimum necessary access validation with AI
  - PCI-DSS data retention policy enforcement automation

- [ ] Lab environments and practice datasets:
  - Realistic (anonymized) datasets for classification practice
  - Sandbox AI data security environments for hands-on practice
  - Privacy compliance simulation platform

- [ ] Hands-on training effectiveness:
  - Participants complete practical exercises (100% completion required to pass)
  - Proficiency assessments show hands-on capability (≥80% pass rate on practical exercises)
  - Training improved actual privacy compliance operations (fewer DSAR delays, faster breach response)

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

### Question 2.2: Comprehensive Privacy Guidance Materials

**Question:** Are comprehensive privacy guidance materials maintained and updated as regulations evolve?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Privacy compliance runbooks maintained:
  - Handling DSAR (Data Subject Access Requests) - step-by-step procedures with AI assistance
  - Conducting DPIA (Data Protection Impact Assessment) for new AI systems
  - Responding to privacy breach detected by AI
  - Fulfilling data subject rights (access, rectification, erasure, portability, objection)
  - Managing consent and legitimate interest assessments

- [ ] Data classification guides available:
  - Detailed guidance on classifying different data types
  - Examples of PII, PHI, PCI, confidential data, trade secrets
  - Region-specific classification requirements (EU vs US vs Asia-Pacific)
  - Industry-specific data types (healthcare, financial services, retail)
  - AI classification accuracy expectations and when to override AI recommendations

- [ ] AI decision frameworks documented:
  - When to trust AI data classification vs. when to override
  - Escalation criteria for privacy-sensitive decisions
  - Human-in-the-loop requirements for different data sensitivity levels
  - AI explainability requirements (how to explain AI data decisions to data subjects)

- [ ] Privacy templates and checklists:
  - DPIA templates tailored for AI data security systems
  - Privacy Impact Assessment checklists
  - Regulatory compliance checklists (GDPR, CCPA, HIPAA, PCI-DSS)
  - Data subject rights request response templates
  - Privacy notice templates (employees, customers, third parties)

- [ ] Ethical AI privacy guidance:
  - Fairness in AI data classification (avoiding bias in access monitoring)
  - Transparency requirements (explaining AI data decisions to data subjects)
  - Accountability frameworks (who is responsible for AI privacy errors?)
  - Purpose limitation enforcement (AI uses data only for stated security purposes)

- [ ] Guidance materials organization and accessibility:
  - Privacy knowledge base with search and tagging
  - Integration with privacy management platforms
  - Mobile access for privacy on-call teams
  - Multilingual materials for global operations (where applicable)

- [ ] Regular updates as regulations evolve:
  - Guidance reviewed and updated at least quarterly
  - Updates triggered by new privacy laws, GDPR guidance updates, regulatory enforcement trends
  - Change log maintained showing guidance update history
  - Teams notified of material guidance changes within 7 days

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

### Question 2.3: Privacy Training Effectiveness Measurement

**Question:** Is privacy training effectiveness measured through competency assessments, compliance metrics, and regulatory audit performance?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Privacy competency assessments implemented:
  - Pre-training and post-training knowledge assessments
  - Regulatory knowledge testing (GDPR, CCPA, HIPAA requirements)
  - AI privacy understanding testing (Article 22, automated decision-making, profiling)
  - Target: ≥20% improvement from pre-training to post-training
  - Annual competency re-assessment to ensure knowledge retention

- [ ] Privacy compliance metrics tracked:
  - **Reduced Privacy Incidents**: Fewer AI data misclassifications, faster incident detection (target: ≥30% reduction year-over-year)
  - **Faster DSAR Response**: Data Subject Access Request fulfillment time (target: ≤30 days GDPR requirement, ≤45 days CCPA requirement)
  - **Improved DPIA Quality**: Data Protection Impact Assessments completed more thoroughly (fewer regulatory findings in audits)
  - **Access Certification Accuracy**: Fewer inappropriate access grants (target: ≥95% certification accuracy)
  - **DLP False Positive Reduction**: Improved tuning of AI DLP policies (target: ≤10% false positive rate)

- [ ] Behavioral measurement:
  - Privacy-by-design adoption increased (privacy considered in design phase, not retrofitted)
  - Data minimization practices improved (less unnecessary data collected/retained)
  - AI privacy tuning activities increased (teams actively tune AI classification, don't just accept defaults)
  - Privacy escalations appropriate (teams escalate privacy-sensitive decisions correctly)

- [ ] Cross-functional privacy collaboration evidenced:
  - Privacy, security, and legal teams jointly address AI privacy challenges
  - Regular cross-functional privacy meetings (at least monthly)
  - Shared privacy incident response (security detects, privacy assesses, legal advises)
  - Joint DPIAs for new AI data security systems

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

## Level 3: Industry-Leading (7-9 points)

### Question 3.1: Privacy Community of Practice with Continuous Learning

**Question:** Is there an active privacy community of practice with continuous learning on AI data privacy and regulatory trends?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Privacy Guild established:
  - Regular meetings of privacy practitioners sharing AI data security knowledge (at least monthly)
  - Privacy case studies discussed (what worked, what didn't, lessons learned)
  - Regulatory update discussions (new GDPR guidance, state privacy laws, enforcement actions)
  - Cross-functional participation (privacy, security, legal, engineering, compliance, data governance)

- [ ] Privacy Champions Network:
  - Distributed privacy advocates across business units promoting privacy-by-design with AI
  - Champions receive advanced privacy training
  - Champions facilitate privacy discussions in their business units
  - Regular privacy champion meetings (at least quarterly)

- [ ] Cross-functional collaboration formalized:
  - Privacy, security, legal, and engineering teams collaborate on AI data privacy
  - Joint DPIAs for new AI systems (privacy + security + engineering)
  - Joint privacy architecture reviews
  - Cross-functional privacy incident response exercises (at least annually)

- [ ] Privacy innovation time allocated:
  - Dedicated time for privacy-enhancing technology (PET) exploration
  - Differential privacy experiments
  - Federated learning pilots
  - Homomorphic encryption research
  - Secure multi-party computation evaluation

- [ ] Regulatory trend analysis and ethics discussions:
  - Teams monitor and discuss emerging privacy regulations (new state privacy laws, EDPB guidance, regulatory enforcement actions)
  - Regular ethics forums discussing AI data security ethics (balancing security and privacy, employee monitoring ethics, customer data protection)
  - Privacy ethics framework applied to AI data security decisions

- [ ] Continuous privacy learning programs:
  - **Privacy Office Hours**: Weekly sessions where privacy experts answer AI data security questions
  - **Regulatory Updates**: Immediate training when regulations change (new GDPR guidance within 30 days, new state privacy law training before effective date)
  - **Incident Learning**: Every privacy incident generates documented learning and process improvements
  - **Vendor Privacy Sharing**: Learn from AI data security vendor privacy practices and new capabilities
  - **External Privacy Training**: Teams attend privacy conferences (IAPP events, privacy symposiums), regulatory workshops (target: ≥2 external events per year for privacy team members)

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

### Question 3.2: Industry AI Data Privacy Education Contributions

**Question:** Does your organization publish contributions to industry AI data privacy education and engage with privacy regulators?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Privacy conference presentations:
  - Presented at privacy conferences on AI data security practices (IAPP Summit, privacy symposiums, data protection forums)
  - Target: ≥2 external presentations per year
  - Topics cover real-world AI data privacy challenges and solutions (not just marketing)

- [ ] Regulatory engagement:
  - Participate in regulatory consultations on AI privacy (EDPB, FTC, state privacy authorities)
  - Participate in regulatory sandbox programs
  - Contribute to regulatory guidance development (provide input on AI privacy best practices)
  - Responsive to regulatory inquiries demonstrating privacy program maturity

- [ ] Open-source privacy training materials:
  - Published AI data privacy training materials (privacy compliance labs, DPIA templates, data classification guides)
  - Open-source privacy tools or frameworks shared with community
  - Creative Commons or similar license for educational reuse

- [ ] Academic collaboration:
  - Partner with universities on privacy curriculum development
  - Guest lectures on AI data privacy
  - Privacy research collaboration (joint research projects, published papers)
  - Internship programs for privacy students

- [ ] Privacy certification development:
  - Contribute to privacy certifications for AI (IAPP certifications, ISO 27701 training, privacy-by-design certifications)
  - Support development of AI-specific privacy certification programs

- [ ] Privacy thought leadership:
  - Published blogs, whitepapers, case studies on AI data privacy
  - Topics: balancing security and privacy, privacy-enhancing technologies, ethical AI, privacy-by-design
  - Share real privacy challenges and lessons learned (not just successes)
  - Target: ≥4 thought leadership publications per year

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

### Question 3.3: Rigorous Privacy Training Effectiveness Measurement with Quantified Improvements

**Question:** Is privacy training effectiveness rigorously measured with quantified compliance improvements, data subject satisfaction, and privacy ROI?

**Answer:** ☐ Yes ☐ No

**Evidence Required:**
- [ ] Privacy competency assessment program:
  - Regular testing of privacy knowledge (baseline and post-training assessments)
  - Regulatory knowledge proficiency measured (GDPR, CCPA, HIPAA requirements)
  - AI privacy understanding validated (automated decision-making, profiling, explainability)
  - Target: ≥90% proficiency score for privacy-critical roles
  - Annual re-certification to ensure knowledge retention

- [ ] Privacy compliance metrics with quantified improvements:
  - **Privacy Incident Reduction**: Year-over-year reduction measured (target: ≥50% reduction after training program)
  - **DSAR Response Time**: Faster Data Subject Access Request fulfillment (target: ≤15 days average, well below 30-day GDPR requirement)
  - **DPIA Quality**: Improved Data Protection Impact Assessment completeness (target: zero regulatory findings in DPIAs during audits)
  - **Access Certification Accuracy**: Improved access review accuracy (target: ≥98% appropriate access, ≤2% overprivileged accounts)
  - **DLP Tuning**: Reduced false positives from AI DLP (target: ≤5% false positive rate)

- [ ] Privacy ROI quantified:
  - **Avoided Regulatory Fines**: Estimate fines avoided due to improved compliance (based on regulatory enforcement trends)
  - **Reduced Breach Impact**: Quantify breach cost reduction from faster detection and response
  - **Customer Trust Improvements**: Measure customer satisfaction with privacy practices (surveys, NPS scores)
  - **Operational Efficiency**: Quantify time savings from AI-assisted privacy operations (DSAR fulfillment, DPIA automation)
  - Target: Privacy training ROI ≥3:1 (benefits exceed costs by 3x)

- [ ] Behavioral measurement validated:
  - **Privacy-by-Design Adoption**: Measured increase in privacy considerations during design phase (target: ≥80% of new AI systems include DPIA before deployment)
  - **Data Minimization**: Measured reduction in unnecessary data collection/retention (target: ≥30% reduction in retained personal data volume)
  - **AI Privacy Tuning**: Measured increase in AI classification tuning activities (target: ≥70% of data security teams actively tune AI monthly)
  - **Appropriate Escalations**: Privacy-sensitive decisions escalated correctly (target: ≥95% appropriate escalations, ≤5% inappropriate escalations)

- [ ] Regulatory audit performance measured:
  - Fewer audit findings after training (target: ≥60% reduction in privacy audit findings)
  - Faster evidence production during audits (target: ≤24 hours to produce requested evidence)
  - Better regulator interactions (positive feedback from regulators on privacy program maturity)

- [ ] Data subject satisfaction measured:
  - **DSAR Fulfillment Quality**: Data subjects satisfied with DSAR responses (target: ≥90% satisfaction)
  - **Response Timeliness**: DSAR fulfilled within required timeframes (target: ≥98% on-time)
  - **Privacy Complaint Rates**: Reduced data subject complaints (target: ≤5 privacy complaints per 10,000 data subjects annually)
  - **Privacy Request Handling**: Efficient handling of data subject rights requests (access, rectification, erasure, portability, objection)

- [ ] Continuous privacy training improvement:
  - Quarterly privacy training program reviews with DPO
  - Privacy training strategy informed by regulatory trends and incident learning
  - Personalized privacy learning paths (role-based, jurisdiction-specific, system-specific)
  - Privacy training integrated into career development (privacy skills required for promotion, privacy certifications supported)

**Evidence Location:** ___________________________________________

**Notes:**
___________________________________________________________________
___________________________________________________________________

---

## Scoring Guide

### Simplified Scoring Method
- **Level 1 (Foundational)**: All 3 questions in Level 1 answered "Yes" = 3 points
- **Level 2 (Comprehensive)**: All 3 questions in Level 1 AND Level 2 answered "Yes" = 6 points
- **Level 3 (Industry-Leading)**: All 9 questions answered "Yes" = 9 points

### Precise Scoring Method
- Each question worth 1 point
- Partial credit: If ≥70% of evidence checkboxes completed = 0.7 points, ≥50% = 0.5 points
- **Total Score**: Sum of all question scores (0-9 points)
- **Maturity Level**:
  - 0-3 points: Level 1 (Foundational) or below
  - 4-6 points: Level 2 (Comprehensive)
  - 7-9 points: Level 3 (Industry-Leading)

**Your Score:** _______ / 9 points

**Your Maturity Level:** _______________________

---

## Evidence Repository

| Question | Evidence Description | Location/Link | Date |
|----------|---------------------|---------------|------|
| 1.1 | Privacy and AI data security training materials | | |
| 1.1 | Training completion dashboard | | |
| 1.2 | Privacy awareness campaign materials | | |
| 1.2 | Privacy notices and employee communications | | |
| 1.3 | Privacy training tracking system reports | | |
| 2.1 | Role-based privacy training curricula | | |
| 2.1 | Hands-on privacy compliance lab scenarios | | |
| 2.2 | Privacy compliance runbooks and guidance | | |
| 2.2 | Data classification guides | | |
| 2.3 | Privacy competency assessment results | | |
| 2.3 | Privacy compliance metrics dashboard | | |
| 3.1 | Privacy Guild meeting notes and attendance | | |
| 3.1 | Privacy Champions Network documentation | | |
| 3.2 | Privacy conference presentations and publications | | |
| 3.2 | Regulatory engagement evidence | | |
| 3.3 | Privacy training effectiveness measurement reports | | |
| 3.3 | Privacy ROI analysis | | |

---

## Data Domain-Specific Notes

### Privacy Regulatory Context
This questionnaire addresses education and guidance for AI-driven data security within complex privacy regulatory environments including GDPR, CCPA/CPRA, HIPAA, PCI-DSS, PIPEDA, and emerging state and international privacy laws.

### Key Privacy Training Topics
- **GDPR Article 22**: Automated individual decision-making and profiling
- **GDPR Article 25**: Privacy-by-design and privacy-by-default
- **GDPR Article 35**: Data Protection Impact Assessments (DPIAs)
- **CCPA/CPRA**: Consumer rights, automated decision-making opt-outs, sensitive personal information
- **Cross-Border Transfers**: Standard Contractual Clauses, adequacy decisions, data localization
- **Privacy-Enhancing Technologies (PETs)**: Differential privacy, federated learning, homomorphic encryption

### Cultural and Regional Considerations
Privacy education must be culturally appropriate and legally accurate for each jurisdiction. European privacy-focused training differs from US sectoral approach. Employee monitoring training must address different cultural norms (European works councils vs. US employment-at-will).

### AI-Specific Privacy Challenges
- **Explainability**: How to explain AI data classification decisions to data subjects
- **Bias**: Understanding and mitigating bias in AI data security (discriminatory access monitoring, unfair classification)
- **Automated Decision-Making**: GDPR Article 22 and CCPA rights regarding automated decisions
- **AI as Data Processor**: Understanding AI vendor roles and liabilities under privacy regulations

### Privacy-Enhancing Technologies (PETs)
Level 3 organizations should educate teams on:
- **Differential Privacy**: Adding noise to datasets to protect individual privacy while preserving statistical utility
- **Federated Learning**: Training AI models on distributed data without centralizing sensitive data
- **Homomorphic Encryption**: Performing computations on encrypted data without decryption
- **Secure Multi-Party Computation (SMPC)**: Collaborative data analysis without revealing individual inputs
- **Zero-Knowledge Proofs**: Proving knowledge without revealing the underlying data

---

## Assessment Summary

**Assessment Date:** _____________________

**Assessor Name:** _____________________

**Organization/Team:** _____________________

**Current Maturity Level:** _____________________

### Strengths
___________________________________________________________________
___________________________________________________________________
___________________________________________________________________

### Gaps
___________________________________________________________________
___________________________________________________________________
___________________________________________________________________

### Recommended Improvements
___________________________________________________________________
___________________________________________________________________
___________________________________________________________________

### Next Assessment Date:** _____________________

---

**Document Version:** HAIAMM v2.1
**Practice:** Education & Guidance (EG)
**Domain:** Data
**Questionnaire Version:** 1.0
**Last Updated:** December 2025
