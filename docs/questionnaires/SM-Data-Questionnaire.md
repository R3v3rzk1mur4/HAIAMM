# Strategy & Metrics (SM) - Data Domain
## HAIAMM Assessment Questionnaire v2.0

**Practice:** Strategy & Metrics (SM)
**Domain:** Data
**Purpose:** Assess organizational maturity in strategic planning and metrics for Human Assisted Intelligence in data security and privacy

---

## Instructions

- Answer each question honestly based on **current, implemented practices** (not plans or aspirations)
- **"Yes" requires evidence** - Document proof for each affirmative answer
- **Answer progressively** - Complete all Level 1 questions before Level 2
- **Level progression** - Achieve ALL questions at lower level before advancing
- **Partial implementation = "No"** - Practice must be complete and systematic

---

## Level 1: Foundational
**Objective:** Establish unified roadmap for data security operated by AI

### Question 1: Risk Assessment and HAI Inventory for Data Security

**Q1.1:** Have you created an inventory of Human Assisted Intelligence systems that perform data security functions (e.g., data classification, DLP, access monitoring, privacy compliance scanning, encryption management) and assessed the risks of AI-driven data decisions?

**Evidence Required:**
- [ ] Documented inventory listing all HAI systems used for data security/privacy
- [ ] Critical data assets identified (PII, PHI, financial records, IP)
- [ ] Risk assessment of AI failure scenarios (misclassification, failed access detection, compliance violations)
- [ ] Business and regulatory impact analysis (GDPR fines, HIPAA violations, data breaches)
- [ ] Document dated within last 12 months

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

### Question 2: Strategic Roadmap for AI Data Security

**Q1.2:** Do you have a documented strategic roadmap for governing Human Assisted Intelligence in data security, including executive sponsorship (CISO/CPO/CIO), governance structure, and basic effectiveness metrics?

**Evidence Required:**
- [ ] 12-18 month strategic roadmap document for AI data security
- [ ] Identified executive sponsor (CISO, Chief Privacy Officer, CIO)
- [ ] Defined governance structure (cross-functional: Security + Privacy + Legal)
- [ ] Basic metrics established (# of AI agents, data classified/monitored, compliance coverage)
- [ ] Roadmap addresses regulatory auditability of AI data decisions
- [ ] Roadmap approved by leadership

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

### Question 3: Foundational Threat Intelligence for Data Security

**Q1.3:** Have you integrated foundational threat intelligence sources (such as HaveIBeenPwned, privacy regulator databases, CISA data security alerts) into your HAI data security tools to improve threat detection and classification decisions?

**Evidence Required:**
- [ ] Threat intelligence sources identified (breach databases, privacy regulators, CISA alerts)
- [ ] Integration with at least 70% of HAI data security tools (DLP, classification, access monitoring)
- [ ] Evidence of enrichment (data security findings include threat intelligence context)
- [ ] Metrics showing threat intelligence improves detection (≥20% increase in detecting data exfiltration)
- [ ] Critical data breach intelligence consumed within 24 hours

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

**Level 1 Score:** _____ / 3 questions answered "Yes"

**Level 1 Achieved:** ☐ Yes (3/3) ☐ No (< 3/3)

---

## Level 2: Comprehensive
**Objective:** Classify data assets and measure AI agent effectiveness by sensitivity level

**Prerequisites:** ALL Level 1 questions must be "Yes" to proceed to Level 2

### Question 4: Data Classification and Risk-Based AI Oversight

**Q2.1:** Have you classified your data assets into sensitivity tiers (e.g., Restricted, Confidential, Internal, Public) based on regulatory requirements and business impact, with differentiated levels of HAI autonomy and human oversight for each tier?

**Evidence Required:**
- [ ] Data classification framework documented (Restricted/Confidential/Internal/Public or similar)
- [ ] Classification considers: sensitivity, regulatory scope (GDPR/HIPAA/PCI-DSS/CCPA), business impact
- [ ] Different HAI oversight levels defined for each tier (e.g., Restricted = human approves access, Public = AI autonomous)
- [ ] All critical data assets classified according to framework
- [ ] Classification addresses data lifecycle stages (creation, storage, processing, sharing, deletion)
- [ ] Classification reviewed and updated at least annually

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

### Question 5: Per-Classification Data Security Effectiveness Metrics

**Q2.2:** Do you measure HAI data security effectiveness separately for each data sensitivity tier, tracking metrics such as classification accuracy, access anomaly detection rate, false positive rate, and privacy compliance coverage?

**Evidence Required:**
- [ ] Metrics defined for each data classification tier
- [ ] Tracking classification accuracy (% of data correctly classified by AI, validated by humans)
- [ ] Tracking access anomaly detection rate (% of unauthorized access detected)
- [ ] Tracking false positive rate (% of incorrect AI alerts)
- [ ] Tracking privacy compliance coverage (% of regulated data monitored by AI)
- [ ] Goals established per tier (e.g., Restricted: >95% classification accuracy, <5% false positives)
- [ ] Human correction rate tracked (how often humans override AI decisions)
- [ ] Metrics reviewed at least quarterly

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

### Question 6: Data Threat Intelligence Classification and ROI

**Q2.3:** Have you classified data threats by organizational relevance (based on your industry, data types, regulatory jurisdiction) and demonstrated measurable ROI from threat intelligence integration in data security?

**Evidence Required:**
- [ ] Threat classification framework (Critical, High, Medium, Low relevance)
- [ ] Classification based on organization's context (industry-specific threats, credential exposure, regulatory enforcement)
- [ ] Different AI response actions for each threat class (Critical = immediate investigation, Low = informational)
- [ ] Evidence of cross-domain threat correlation (Data + Endpoints, Data + Vendors)
- [ ] ROI metrics documented (breach prevention, regulatory fine avoidance, faster incident response)
- [ ] Target ROI ≥3:1 achieved or tracked toward

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

**Level 2 Score:** _____ / 3 questions answered "Yes"

**Level 2 Achieved:** ☐ Yes (3/3) ☐ No (< 3/3)

---

## Level 3: Industry-Leading
**Objective:** Demonstrate data security ROI and contribute original privacy/data threat intelligence

**Prerequisites:** ALL Level 2 questions must be "Yes" to proceed to Level 3

### Question 7: Industry Benchmarking for AI Data Security

**Q3.1:** Do you conduct periodic (at least annually) industry-wide cost comparisons for HAI data security, benchmarking your investment and effectiveness against industry peers and data breach trends?

**Evidence Required:**
- [ ] Annual benchmarking analysis completed for AI data security
- [ ] Comparison metrics documented (cost per data asset protected, breach prevention, compliance coverage)
- [ ] External data sources used (industry breach reports, privacy regulator enforcement data, peer benchmarking)
- [ ] Results shared with executive leadership (CISO/CPO/Board)
- [ ] Benchmarking drives investment decisions (DLP tools, classification systems, privacy automation)

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

### Question 8: Historical ROI Tracking for Data Security

**Q3.2:** Do you collect and analyze historical data (minimum 12 months) on HAI data security spend correlated with measurable outcomes such as breach prevention, regulatory fine avoidance, privacy compliance improvements, and demonstrable ROI?

**Evidence Required:**
- [ ] Historical tracking (12+ months) of HAI data security investment
- [ ] Breach prevention metrics (unauthorized access blocked, data exfiltration prevented)
- [ ] Regulatory compliance metrics (GDPR/CCPA compliance coverage, audit findings reduced)
- [ ] Privacy incident metrics (privacy violations detected/prevented, data subject request response time)
- [ ] ROI calculated (breach cost avoidance, regulatory fine prevention, privacy team productivity)
- [ ] Executive-level ROI presentation delivered to leadership/board
- [ ] Evidence of investment decisions based on ROI analysis

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

### Question 9: Original Data Threat Intelligence Production and Sharing

**Q3.3:** Do you produce and share original data security/privacy threat intelligence with the industry through breach trend analysis, privacy incident reporting, data exfiltration technique documentation, or participation in data-focused ISACs?

**Evidence Required:**
- [ ] At least 2 original threat intelligence contributions per year
- [ ] Contributions include: breach trend analysis, privacy incident patterns, data exfiltration techniques, or dark web exposure reports
- [ ] Public evidence (blog posts, conference presentations, industry reports, ISAC contributions)
- [ ] Participation in data security ISACs or privacy threat intelligence sharing communities
- [ ] Documented impact (industry awareness improved, regulatory guidance influenced, peer organizations protected)

**Answer:** ☐ Yes  ☐ No

**Evidence Location:** _________________________________

**Notes:** ___________________________________________

---

**Level 3 Score:** _____ / 3 questions answered "Yes"

**Level 3 Achieved:** ☐ Yes (3/3) ☐ No (< 3/3)

---

## Practice Score Calculation

### Simplified Scoring (Recommended)

```
Level 1 Achieved (all 3 "Yes"): 1.0 point
Level 2 Achieved (all 3 "Yes"): +1.0 point (total 2.0)
Level 3 Achieved (all 3 "Yes"): +1.0 point (total 3.0)
```

**SM-Data Practice Score:** _______ / 3.0

### Precise Scoring (For Formal Audits)

```
L1_score = (L1 "Yes" answers) / 3
L2_score = (L2 "Yes" answers) / 3 × L1_score
L3_score = (L3 "Yes" answers) / 3 × L2_score

Practice Score = L1_score + L2_score + L3_score
```

**SM-Data Practice Score (Precise):** _______ / 3.0

---

## Assessment Summary

**Assessment Date:** _________________________________

**Assessor(s):** _____________________________________

**HAI System(s) Assessed:** __________________________

**Data Assets in Scope:** ____________________________

**Overall Maturity Level:**
- ☐ Level 0 (Score < 1.0): Ad-hoc, no formal strategic planning for data security
- ☐ Level 1 (Score 1.0 - 1.9): Foundational roadmap and metrics for AI data security
- ☐ Level 2 (Score 2.0 - 2.9): Comprehensive data classification and measurement
- ☐ Level 3 (Score 3.0): Industry-leading data security ROI and threat intelligence contribution

**Strengths:**

_________________________________________________________________

**Gaps:**

_________________________________________________________________

**Priority Improvements:**

_________________________________________________________________

**Re-Assessment Date:** _________________________________

---

## Evidence Repository

Link all evidence documents here for audit trail:

| Question | Evidence Document | Location | Date | Owner |
|----------|------------------|----------|------|-------|
| Q1.1 | | | | |
| Q1.2 | | | | |
| Q1.3 | | | | |
| Q2.1 | | | | |
| Q2.2 | | | | |
| Q2.3 | | | | |
| Q3.1 | | | | |
| Q3.2 | | | | |
| Q3.3 | | | | |

---

**Document Version:** 2.0
**Last Updated:** 2025-12-29
**Next Review:** Quarterly or after significant HAI system changes

---

## Data Security Specific Notes

**Regulatory Considerations:**
- [ ] GDPR compliance assessed (if EU data subjects)
- [ ] CCPA compliance assessed (if California residents)
- [ ] HIPAA compliance assessed (if health data)
- [ ] PCI-DSS compliance assessed (if payment data)

**Data Privacy Team Involvement:**
- [ ] Chief Privacy Officer or equivalent involved in assessment
- [ ] Legal team reviewed AI data decision-making governance
- [ ] Data Protection Officer consulted (if required by GDPR)

**Cross-Domain Dependencies:**
- [ ] Data classification integrated with Endpoint security (data at rest on devices)
- [ ] Data monitoring coordinated with Infrastructure security (data in transit/storage)
- [ ] Vendor data access governed (third-party data processors)
